#!/usr/bin/env python3
"""
QuantumSpectre Elite Trading System
Intelligence System Service

This module implements the main Intelligence service responsible for:
- Coordinating pattern recognition across multiple timeframes and assets
- Detecting and exploiting market loopholes and inefficiencies
- Managing the adaptive learning and evolution of trading strategies
- Integrating multiple intelligence sources for high-confidence signals

The Intelligence system is designed to deliver high win rates by combining
multiple analysis techniques and continuously adapting to market conditions.
"""

import os
import sys
import time
import signal
import asyncio
import logging
import threading
import multiprocessing as mp
from typing import Dict, List, Set, Any, Optional, Tuple, Union, Callable
from datetime import datetime, timedelta
import json
import uuid
import concurrent.futures
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
from dataclasses import dataclass, field
from enum import Enum, auto
import numpy as np
import pandas as pd

# Internal imports
from config import Config
from common.logger import get_logger
from common.utils import (
    ThreadSafeDict, create_event_loop, run_in_executor, 
    benchmark, serialize_numpy, deserialize_numpy
)
from common.constants import (
    TIMEFRAMES, ASSETS, PATTERN_RECOGNITION_TIMEFRAMES,
    LOOPHOLE_DETECTION_INTERVAL, ASSET_BLACKLIST,
    ADAPTIVE_LEARNING_SCHEDULE, DEFAULT_SERVICE_TIMEOUT,
    MARKET_REGIMES, SIGNAL_CONFIDENCE_LEVELS
)
from common.exceptions import (
    IntelligenceError, PatternRecognitionError, LoopholeDetectionError,
    AdaptiveLearningError, IntelligenceServiceError
)
from common.metrics import MetricsCollector
from common.async_utils import (
    AsyncTaskManager, create_throttled_task, 
    cancelable_periodic_task, gather_with_concurrency
)

# Intelligence system imports
from intelligence import (
    intelligence, register_pattern_recognizer, register_loophole_detector,
    register_adaptive_learner, get_pattern_recognizer, get_loophole_detector,
    get_adaptive_learner, list_pattern_recognizers, list_loophole_detectors,
    list_adaptive_learners
)

# Import Intelligence components
from intelligence.pattern_recognition import pattern_recognition_manager
from intelligence.loophole_detection import loophole_detection_manager
from intelligence.adaptive_learning import adaptive_learning_manager
from intelligence.online_learner import OnlineLearner

# Create logger
logger = get_logger("intelligence.app")


class IntelligenceSignalType(Enum):
    """Signal types generated by the intelligence system"""
    PATTERN_RECOGNITION = auto()
    LOOPHOLE_DETECTION = auto()
    MARKET_REGIME = auto()
    SUPPORT_RESISTANCE = auto()
    VOLATILITY_REGIME = auto()
    TREND_DIRECTION = auto()
    REVERSALS = auto()
    DIVERGENCE = auto()
    VOLUME_PROFILE = auto()
    ORDER_FLOW = auto()
    SENTIMENT = auto()
    CORRELATED_ASSET = auto()
    BREAKOUT = auto()
    LIQUIDITY_ZONE = auto()
    INSTITUTIONAL_ACTIVITY = auto()


class IntelligenceActionType(Enum):
    """Action types that can be recommended by the intelligence system"""
    BUY = auto()
    SELL = auto()
    HOLD = auto()
    EXIT_LONG = auto()
    EXIT_SHORT = auto()
    REDUCE_POSITION = auto()
    INCREASE_POSITION = auto()
    AWAIT_CONFIRMATION = auto()
    MARKET_NEUTRAL = auto()


class SignalConfidence(Enum):
    """Confidence levels for intelligence signals"""
    VERY_LOW = 1
    LOW = 2
    MEDIUM = 3
    HIGH = 4
    VERY_HIGH = 5
    EXCEPTIONAL = 6


@dataclass
class IntelligenceSignal:
    """
    Intelligence signal generated by the system with metadata and context
    """
    id: str = field(default_factory=lambda: str(uuid.uuid4()))
    timestamp: datetime = field(default_factory=datetime.utcnow)
    asset: str = ""
    timeframe: str = ""
    signal_type: IntelligenceSignalType = None
    action: IntelligenceActionType = None
    confidence: SignalConfidence = SignalConfidence.MEDIUM
    source_component: str = ""
    expiration: Optional[datetime] = None
    metadata: Dict[str, Any] = field(default_factory=dict)
    context: Dict[str, Any] = field(default_factory=dict)
    related_signals: List[str] = field(default_factory=list)
    
    def is_valid(self) -> bool:
        """Check if the signal is still valid (not expired)"""
        if not self.expiration:
            return True
        return datetime.utcnow() < self.expiration
    
    def to_dict(self) -> dict:
        """Convert signal to dictionary for serialization"""
        return {
            "id": self.id,
            "timestamp": self.timestamp.isoformat(),
            "asset": self.asset,
            "timeframe": self.timeframe,
            "signal_type": self.signal_type.name if self.signal_type else None,
            "action": self.action.name if self.action else None,
            "confidence": self.confidence.name,
            "confidence_value": self.confidence.value,
            "source_component": self.source_component,
            "expiration": self.expiration.isoformat() if self.expiration else None,
            "metadata": {k: serialize_numpy(v) for k, v in self.metadata.items()},
            "context": {k: serialize_numpy(v) for k, v in self.context.items()},
            "related_signals": self.related_signals
        }
    
    @classmethod
    def from_dict(cls, data: dict) -> 'IntelligenceSignal':
        """Create signal from dictionary"""
        signal = cls(
            id=data["id"],
            timestamp=datetime.fromisoformat(data["timestamp"]),
            asset=data["asset"],
            timeframe=data["timeframe"],
            signal_type=IntelligenceSignalType[data["signal_type"]] if data["signal_type"] else None,
            action=IntelligenceActionType[data["action"]] if data["action"] else None,
            confidence=SignalConfidence[data["confidence"]],
            source_component=data["source_component"],
            expiration=datetime.fromisoformat(data["expiration"]) if data["expiration"] else None,
            metadata={k: deserialize_numpy(v) for k, v in data["metadata"].items()},
            context={k: deserialize_numpy(v) for k, v in data["context"].items()},
            related_signals=data["related_signals"]
        )
        return signal


class IntelligenceService:
    """
    Main Intelligence Service for the QuantumSpectre Elite Trading System
    
    This service coordinates all intelligence components, including pattern
    recognition, loophole detection, and adaptive learning systems to generate
    high-confidence trading signals with consistently strong performance.
    """
    
    def __init__(self, config: Config):
        """
        Initialize the Intelligence Service
        
        Args:
            config: System configuration
        """
        self.config = config
        self.running = False
        self.ready = False
        self.startup_time = None
        self.shutdown_time = None
        
        # Service components
        self.pattern_recognition = pattern_recognition_manager
        self.loophole_detection = loophole_detection_manager
        self.adaptive_learning = adaptive_learning_manager
        self.online_learner = OnlineLearner(config)
        
        # Signal management
        self.signals = ThreadSafeDict()
        self.active_signals = ThreadSafeDict()
        self.signal_history = ThreadSafeDict()
        self.signal_stats = {}
        
        # Performance tracking
        self.metrics = MetricsCollector("intelligence_service")
        self.component_performance = ThreadSafeDict()
        
        # Task management
        self.task_manager = AsyncTaskManager()
        self.executor = ThreadPoolExecutor(
            max_workers=config.get("intelligence.max_threads", 8),
            thread_name_prefix="intel_"
        )
        self.process_pool = ProcessPoolExecutor(
            max_workers=config.get("intelligence.max_processes", 4)
        )
        
        # Asset and timeframe tracking
        self.active_assets = set()
        self.active_timeframes = set()
        self.asset_timeframe_pairs = set()
        
        # State tracking
        self.market_regimes = ThreadSafeDict()
        self.volatility_regimes = ThreadSafeDict()
        self.asset_correlations = ThreadSafeDict()
        
        # Event listeners
        self.event_listeners = {}
        
        # Asset-specific intelligence cache
        self.asset_intelligence = ThreadSafeDict()
        
        logger.info("Intelligence Service initialized")
    
    async def start(self):
        """Start the Intelligence Service and all components"""
        if self.running:
            logger.warning("Intelligence Service already running")
            return
        
        logger.info("Starting Intelligence Service")
        self.startup_time = datetime.utcnow()
        self.running = True
        
        try:
            # Start component managers
            await self.pattern_recognition.start(self.config)
            await self.loophole_detection.start(self.config)
            await self.adaptive_learning.start(self.config)
            await self.online_learner.start()
            
            # Initialize active assets and timeframes
            self._initialize_tracking()
            
            # Start background tasks
            self._start_background_tasks()
            
            self.ready = True
            startup_duration = (datetime.utcnow() - self.startup_time).total_seconds()
            logger.info(f"Intelligence Service started successfully in {startup_duration:.2f}s")
            self.metrics.gauge("startup_duration_seconds", startup_duration)
            
        except Exception as e:
            self.running = False
            logger.error(f"Failed to start Intelligence Service: {e}")
            raise IntelligenceServiceError(f"Failed to start service: {e}")
    
    async def stop(self):
        """Stop the Intelligence Service and all components"""
        if not self.running:
            logger.warning("Intelligence Service already stopped")
            return
        
        logger.info("Stopping Intelligence Service")
        self.shutdown_time = datetime.utcnow()
        self.running = False
        self.ready = False
        
        try:
            # Stop background tasks
            await self.task_manager.cancel_all_tasks()
            
            # Stop component managers
            await self.online_learner.stop()
            await self.adaptive_learning.stop()
            await self.loophole_detection.stop()
            await self.pattern_recognition.stop()
            
            # Shutdown executors
            self.executor.shutdown(wait=True)
            self.process_pool.shutdown(wait=True)
            
            shutdown_duration = (datetime.utcnow() - self.shutdown_time).total_seconds()
            logger.info(f"Intelligence Service stopped successfully in {shutdown_duration:.2f}s")
            self.metrics.gauge("shutdown_duration_seconds", shutdown_duration)
            
        except Exception as e:
            logger.error(f"Error during Intelligence Service shutdown: {e}")
            raise IntelligenceServiceError(f"Failed to stop service: {e}")
    
    async def reload_config(self, config: Config):
        """
        Reload service configuration
        
        Args:
            config: New configuration
        """
        logger.info("Reloading Intelligence Service configuration")
        self.config = config
        
        # Update component configurations
        await self.pattern_recognition.reload_config(config)
        await self.loophole_detection.reload_config(config)
        await self.adaptive_learning.reload_config(config)
        await self.online_learner.reload_config(config)
        
        # Update tracking settings
        self._initialize_tracking()
        
        logger.info("Intelligence Service configuration reloaded")
    
    async def generate_signals(self, 
                              asset: str, 
                              timeframe: str) -> List[IntelligenceSignal]:
        """
        Generate intelligence signals for a specific asset and timeframe
        
        Args:
            asset: Target asset
            timeframe: Target timeframe
            
        Returns:
            List of generated intelligence signals
        """
        if not self.ready:
            logger.warning("Intelligence Service not ready, cannot generate signals")
            return []
        
        logger.debug(f"Generating intelligence signals for {asset} ({timeframe})")
        signals = []
        
        # Track performance
        with self.metrics.measure_time("signal_generation_seconds", 
                                       {"asset": asset, "timeframe": timeframe}):
            try:
                # Get pattern recognition signals
                pattern_signals = await self.pattern_recognition.analyze(asset, timeframe)
                signals.extend(pattern_signals)
                
                # Get loophole detection signals
                loophole_signals = await self.loophole_detection.analyze(asset, timeframe)
                signals.extend(loophole_signals)
                
                # Process and enhance signals
                enhanced_signals = await self._enhance_signals(signals, asset, timeframe)
                
                # Store active signals
                for signal in enhanced_signals:
                    self.signals[signal.id] = signal
                    self.active_signals[signal.id] = signal
                
                # Update metrics
                self.metrics.counter("signals_generated", len(enhanced_signals),
                                    {"asset": asset, "timeframe": timeframe})
                
                return enhanced_signals
                
            except Exception as e:
                logger.error(f"Error generating signals for {asset} ({timeframe}): {e}")
                self.metrics.counter("signal_generation_errors", 1,
                                   {"asset": asset, "timeframe": timeframe})
                return []
    
    async def get_market_regime(self, asset: str) -> str:
        """
        Get the current market regime for an asset
        
        Args:
            asset: Target asset
            
        Returns:
            Current market regime classification
        """
        if asset in self.market_regimes:
            return self.market_regimes[asset]
        
        # Default to unknown if not yet determined
        return "UNKNOWN"
    
    async def get_volatility_regime(self, asset: str) -> str:
        """
        Get the current volatility regime for an asset
        
        Args:
            asset: Target asset
            
        Returns:
            Current volatility regime classification
        """
        if asset in self.volatility_regimes:
            return self.volatility_regimes[asset]
        
        # Default to medium if not yet determined
        return "MEDIUM"
    
    async def get_correlated_assets(self, asset: str, threshold: float = 0.7) -> List[str]:
        """
        Get list of correlated assets above the threshold
        
        Args:
            asset: Target asset
            threshold: Correlation threshold (0-1)
            
        Returns:
            List of correlated assets with correlation values
        """
        if asset not in self.asset_correlations:
            return []
        
        correlations = self.asset_correlations[asset]
        return [(corr_asset, corr_value) 
                for corr_asset, corr_value in correlations.items() 
                if abs(corr_value) >= threshold]
    
    async def get_asset_intelligence(self, asset: str) -> dict:
        """
        Get comprehensive intelligence data for an asset
        
        Args:
            asset: Target asset
            
        Returns:
            Dictionary with comprehensive intelligence data
        """
        if not self.ready:
            logger.warning("Intelligence Service not ready")
            return {}
        
        if asset in self.asset_intelligence:
            # Return cached data if recent enough (< 60 seconds)
            cached = self.asset_intelligence[asset]
            if (datetime.utcnow() - cached["timestamp"]).total_seconds() < 60:
                return cached
        
        # Gather comprehensive intelligence
        intelligence_data = {
            "asset": asset,
            "timestamp": datetime.utcnow(),
            "market_regime": await self.get_market_regime(asset),
            "volatility_regime": await self.get_volatility_regime(asset),
            "active_signals": await self.get_active_signals(asset),
            "pattern_recognitions": await self.pattern_recognition.get_recent_patterns(asset),
            "detected_loopholes": await self.loophole_detection.get_recent_loopholes(asset),
            "correlated_assets": await self.get_correlated_assets(asset),
            "trading_stats": self._get_asset_trading_stats(asset)
        }
        
        # Cache results
        self.asset_intelligence[asset] = intelligence_data
        
        return intelligence_data
    
    async def get_active_signals(self, asset: str = None) -> List[IntelligenceSignal]:
        """
        Get active intelligence signals, optionally filtered by asset
        
        Args:
            asset: Optional asset to filter signals
            
        Returns:
            List of active intelligence signals
        """
        # Filter expired signals
        now = datetime.utcnow()
        expired_signals = [
            signal_id for signal_id, signal in self.active_signals.items()
            if signal.expiration and now > signal.expiration
        ]
        
        # Remove expired signals from active signals
        for signal_id in expired_signals:
            if signal_id in self.active_signals:
                # Move to history before removing
                self.signal_history[signal_id] = self.active_signals[signal_id]
                del self.active_signals[signal_id]
        
        # Return filtered active signals
        if asset:
            return [
                signal for signal in self.active_signals.values()
                if signal.asset == asset
            ]
        else:
            return list(self.active_signals.values())
    
    async def get_signal_by_id(self, signal_id: str) -> Optional[IntelligenceSignal]:
        """
        Get signal by ID from active signals or history
        
        Args:
            signal_id: Signal ID to retrieve
            
        Returns:
            Signal if found, None otherwise
        """
        if signal_id in self.active_signals:
            return self.active_signals[signal_id]
        
        if signal_id in self.signal_history:
            return self.signal_history[signal_id]
        
        return None
    
    async def evaluate_signal_performance(self, signal_id: str, outcome: bool) -> bool:
        """
        Record the outcome of a signal and update performance metrics
        
        Args:
            signal_id: Signal ID to evaluate
            outcome: Whether the signal led to a successful trade
            
        Returns:
            Whether the evaluation was successful
        """
        signal = await self.get_signal_by_id(signal_id)
        if not signal:
            logger.error(f"Signal {signal_id} not found for performance evaluation")
            return False
        
        logger.debug(f"Evaluating signal {signal_id} performance: {'success' if outcome else 'failure'}")
        
        # Record outcome for adaptive learning
        await self.adaptive_learning.record_signal_outcome(signal, outcome)
        
        # Update online learner
        await self.online_learner.update(signal, outcome)
        
        # Record metrics
        self.metrics.counter("signal_outcomes", 1, {
            "asset": signal.asset,
            "timeframe": signal.timeframe,
            "signal_type": signal.signal_type.name if signal.signal_type else "UNKNOWN",
            "outcome": "success" if outcome else "failure"
        })
        
        # Update signal stats
        self._update_signal_stats(signal, outcome)
        
        return True
    
    def status(self) -> dict:
        """
        Get current status of the Intelligence Service
        
        Returns:
            Status dictionary with comprehensive service information
        """
        return {
            "running": self.running,
            "ready": self.ready,
            "startup_time": self.startup_time.isoformat() if self.startup_time else None,
            "uptime_seconds": (datetime.utcnow() - self.startup_time).total_seconds() if self.startup_time else 0,
            "active_assets": list(self.active_assets),
            "active_timeframes": list(self.active_timeframes),
            "active_signal_count": len(self.active_signals),
            "component_status": {
                "pattern_recognition": self.pattern_recognition.status(),
                "loophole_detection": self.loophole_detection.status(),
                "adaptive_learning": self.adaptive_learning.status(),
                "online_learner": self.online_learner.status()
            },
            "metrics": self.metrics.get_all_metrics(),
            "signal_stats": self.signal_stats
        }
    
    # Private methods
    
    def _initialize_tracking(self):
        """Initialize assets and timeframes to track based on configuration"""
        # Get configured assets and timeframes
        assets = self.config.get("intelligence.assets", ASSETS)
        timeframes = self.config.get("intelligence.timeframes", TIMEFRAMES)
        
        # Filter out blacklisted assets
        blacklist = self.config.get("intelligence.asset_blacklist", ASSET_BLACKLIST)
        assets = [a for a in assets if a not in blacklist]
        
        # Update tracking sets
        self.active_assets = set(assets)
        self.active_timeframes = set(timeframes)
        
        # Create asset-timeframe pairs
        self.asset_timeframe_pairs = {
            (asset, timeframe) 
            for asset in self.active_assets 
            for timeframe in self.active_timeframes
        }
        
        logger.info(f"Tracking {len(self.active_assets)} assets "
                   f"across {len(self.active_timeframes)} timeframes "
                   f"({len(self.asset_timeframe_pairs)} combinations)")
    
    def _start_background_tasks(self):
        """Start background tasks for continuous operation"""
        # Market state monitoring
        self.task_manager.create_task(
            self._monitor_market_regimes(),
            "market_regime_monitor"
        )
        
        # Correlation analysis
        self.task_manager.create_task(
            self._analyze_asset_correlations(),
            "correlation_analysis"
        )
        
        # Signal expiration monitoring
        self.task_manager.create_task(
            self._monitor_signal_expiration(),
            "signal_expiration_monitor"
        )
        
        # Periodic performance evaluation
        self.task_manager.create_task(
            self._evaluate_component_performance(),
            "performance_evaluation"
        )
        
        # Adaptive learning cycle
        self.task_manager.create_task(
            self._run_adaptive_learning_cycle(),
            "adaptive_learning_cycle"
        )
        
        logger.debug("Background tasks started")
    
    async def _enhance_signals(self, 
                              signals: List[IntelligenceSignal],
                              asset: str,
                              timeframe: str) -> List[IntelligenceSignal]:
        """
        Enhance signals with additional context and confidence adjustment
        
        Args:
            signals: List of signals to enhance
            asset: Target asset
            timeframe: Target timeframe
            
        Returns:
            Enhanced signals
        """
        if not signals:
            return []
        
        enhanced_signals = []
        
        # Get market context
        market_regime = await self.get_market_regime(asset)
        volatility_regime = await self.get_volatility_regime(asset)
        
        for signal in signals:
            # Update context information
            signal.context.update({
                "market_regime": market_regime,
                "volatility_regime": volatility_regime,
                "enhancement_timestamp": datetime.utcnow().isoformat()
            })
            
            # Adjust confidence based on regime compatibility
            adjusted_signal = await self._adjust_signal_confidence(signal)
            
            # Add related signals if any
            await self._link_related_signals(adjusted_signal)
            
            enhanced_signals.append(adjusted_signal)
        
        return enhanced_signals
    
    async def _adjust_signal_confidence(self, signal: IntelligenceSignal) -> IntelligenceSignal:
        """
        Adjust signal confidence based on various factors
        
        Args:
            signal: Signal to adjust
            
        Returns:
            Adjusted signal
        """
        # Get base confidence value
        base_confidence = signal.confidence.value
        
        # Factors that affect confidence
        adjustment_factors = []
        
        # Historical performance of this signal type
        type_performance = self._get_signal_type_performance(signal.signal_type)
        if type_performance["count"] > 10:
            performance_factor = type_performance["win_rate"] / 0.5 - 1.0  # Center around 0
            adjustment_factors.append(("historical_performance", performance_factor * 0.5))
        
        # Market regime compatibility
        if "market_regime" in signal.context:
            regime = signal.context["market_regime"]
            compatibility = self._get_regime_compatibility(signal.signal_type, regime)
            adjustment_factors.append(("regime_compatibility", compatibility * 0.3))
        
        # Timeframe alignment
        if signal.timeframe in ["1h", "4h", "1d"]:
            adjustment_factors.append(("timeframe_significance", 0.2))
        
        # Apply adjustments
        total_adjustment = sum(factor[1] for factor in adjustment_factors)
        
        # Calculate new confidence level
        new_confidence_value = max(1, min(6, base_confidence + round(total_adjustment)))
        
        # Map back to enum
        new_confidence = next(level for level in SignalConfidence 
                             if level.value == new_confidence_value)
        
        # Create new signal with adjusted confidence
        adjusted_signal = IntelligenceSignal(
            id=signal.id,
            timestamp=signal.timestamp,
            asset=signal.asset,
            timeframe=signal.timeframe,
            signal_type=signal.signal_type,
            action=signal.action,
            confidence=new_confidence,
            source_component=signal.source_component,
            expiration=signal.expiration,
            metadata=signal.metadata.copy(),
            context=signal.context.copy(),
            related_signals=signal.related_signals.copy()
        )
        
        # Record adjustment factors
        adjusted_signal.context["confidence_adjustment"] = {
            "base_confidence": base_confidence,
            "adjustment_factors": dict(adjustment_factors),
            "total_adjustment": total_adjustment,
            "final_confidence": new_confidence_value
        }
        
        return adjusted_signal
    
    async def _link_related_signals(self, signal: IntelligenceSignal) -> None:
        """
        Find and link related signals to provide a more comprehensive view
        
        Args:
            signal: Signal to link related signals to
        """
        # Find related signals from active signals
        related_signals = []
        
        for active_id, active_signal in self.active_signals.items():
            # Skip self
            if active_id == signal.id:
                continue
                
            # Link signals for same asset
            if active_signal.asset == signal.asset:
                # Link signals from different timeframes
                if active_signal.timeframe != signal.timeframe:
                    related_signals.append(active_id)
                
                # Link signals of complementary types
                if (signal.signal_type and active_signal.signal_type and
                    self._are_complementary_signal_types(signal.signal_type, active_signal.signal_type)):
                    related_signals.append(active_id)
        
        # Limit to most relevant signals (maximum 5)
        if len(related_signals) > 5:
            related_signals = related_signals[:5]
        
        # Update signal's related signals list
        signal.related_signals.extend(related_signals)
    
    def _are_complementary_signal_types(self, type1: IntelligenceSignalType, 
                                      type2: IntelligenceSignalType) -> bool:
        """
        Determine if two signal types are complementary
        
        Args:
            type1: First signal type
            type2: Second signal type
            
        Returns:
            Whether the signal types are complementary
        """
        # Define complementary signal type pairs
        complementary_pairs = [
            {IntelligenceSignalType.PATTERN_RECOGNITION, IntelligenceSignalType.VOLUME_PROFILE},
            {IntelligenceSignalType.SUPPORT_RESISTANCE, IntelligenceSignalType.BREAKOUT},
            {IntelligenceSignalType.TREND_DIRECTION, IntelligenceSignalType.MOMENTUM},
            {IntelligenceSignalType.DIVERGENCE, IntelligenceSignalType.REVERSALS},
            {IntelligenceSignalType.ORDER_FLOW, IntelligenceSignalType.LIQUIDITY_ZONE},
            {IntelligenceSignalType.SENTIMENT, IntelligenceSignalType.INSTITUTIONAL_ACTIVITY}
        ]
        
        # Check if types are in any complementary pair
        return any({type1, type2} == pair for pair in complementary_pairs)
    
    def _get_signal_type_performance(self, signal_type: IntelligenceSignalType) -> dict:
        """
        Get historical performance metrics for a signal type
        
        Args:
            signal_type: Signal type to get performance for
            
        Returns:
            Performance statistics
        """
        if not signal_type:
            return {"count": 0, "wins": 0, "losses": 0, "win_rate": 0.5}
        
        # Get stats from signal_stats dict
        type_name = signal_type.name
        if type_name in self.signal_stats:
            stats = self.signal_stats[type_name]
            if stats["count"] > 0:
                win_rate = stats["wins"] / stats["count"]
            else:
                win_rate = 0.5
            
            return {
                "count": stats["count"],
                "wins": stats["wins"],
                "losses": stats["losses"],
                "win_rate": win_rate
            }
        
        # Default if no stats available
        return {"count": 0, "wins": 0, "losses": 0, "win_rate": 0.5}
    
    def _get_regime_compatibility(self, signal_type: IntelligenceSignalType, 
                                 regime: str) -> float:
        """
        Get compatibility score between signal type and market regime
        
        Args:
            signal_type: Signal type to check
            regime: Market regime to check
            
        Returns:
            Compatibility score (-1 to 1)
        """
        if not signal_type:
            return 0.0
        
        # Define compatibility map
        compatibility = {
            "TRENDING_UP": {
                IntelligenceSignalType.PATTERN_RECOGNITION: 0.5,
                IntelligenceSignalType.TREND_DIRECTION: 0.8,
                IntelligenceSignalType.BREAKOUT: 0.7,
                IntelligenceSignalType.REVERSALS: -0.3,
                IntelligenceSignalType.SUPPORT_RESISTANCE: 0.4
            },
            "TRENDING_DOWN": {
                IntelligenceSignalType.PATTERN_RECOGNITION: 0.5,
                IntelligenceSignalType.TREND_DIRECTION: 0.8,
                IntelligenceSignalType.BREAKOUT: 0.7,
                IntelligenceSignalType.REVERSALS: -0.3,
                IntelligenceSignalType.SUPPORT_RESISTANCE: 0.4
            },
            "RANGING": {
                IntelligenceSignalType.SUPPORT_RESISTANCE: 0.8,
                IntelligenceSignalType.PATTERN_RECOGNITION: 0.4,
                IntelligenceSignalType.TREND_DIRECTION: -0.2,
                IntelligenceSignalType.BREAKOUT: -0.4,
                IntelligenceSignalType.REVERSALS: 0.6
            },
            "VOLATILE": {
                IntelligenceSignalType.BREAKOUT: 0.6,
                IntelligenceSignalType.LIQUIDITY_ZONE: 0.7,
                IntelligenceSignalType.PATTERN_RECOGNITION: -0.2,
                IntelligenceSignalType.SUPPORT_RESISTANCE: -0.3,
                IntelligenceSignalType.ORDER_FLOW: 0.5
            },
            "CHOPPY": {
                IntelligenceSignalType.ORDER_FLOW: 0.6,
                IntelligenceSignalType.LIQUIDITY_ZONE: 0.5,
                IntelligenceSignalType.INSTITUTIONAL_ACTIVITY: 0.7,
                IntelligenceSignalType.PATTERN_RECOGNITION: -0.5,
                IntelligenceSignalType.TREND_DIRECTION: -0.6
            }
        }
        
        # Get compatibility score
        if regime in compatibility and signal_type in compatibility[regime]:
            return compatibility[regime][signal_type]
        
        # Default compatibility
        return 0.0
    
    def _update_signal_stats(self, signal: IntelligenceSignal, outcome: bool) -> None:
        """
        Update signal statistics based on trade outcome
        
        Args:
            signal: Signal that was evaluated
            outcome: Whether the trade was successful
        """
        if not signal.signal_type:
            return
        
        type_name = signal.signal_type.name
        
        # Initialize stats if not exists
        if type_name not in self.signal_stats:
            self.signal_stats[type_name] = {
                "count": 0,
                "wins": 0,
                "losses": 0,
                "by_timeframe": {},
                "by_asset": {}
            }
        
        # Update general stats
        stats = self.signal_stats[type_name]
        stats["count"] += 1
        if outcome:
            stats["wins"] += 1
        else:
            stats["losses"] += 1
        
        # Update timeframe stats
        if signal.timeframe not in stats["by_timeframe"]:
            stats["by_timeframe"][signal.timeframe] = {"count": 0, "wins": 0, "losses": 0}
        
        tf_stats = stats["by_timeframe"][signal.timeframe]
        tf_stats["count"] += 1
        if outcome:
            tf_stats["wins"] += 1
        else:
            tf_stats["losses"] += 1
        
        # Update asset stats
        if signal.asset not in stats["by_asset"]:
            stats["by_asset"][signal.asset] = {"count": 0, "wins": 0, "losses": 0}
        
        asset_stats = stats["by_asset"][signal.asset]
        asset_stats["count"] += 1
        if outcome:
            asset_stats["wins"] += 1
        else:
            asset_stats["losses"] += 1
    
    def _get_asset_trading_stats(self, asset: str) -> dict:
        """
        Get trading statistics for a specific asset
        
        Args:
            asset: Asset to get statistics for
            
        Returns:
            Trading statistics for the asset
        """
        stats = {
            "total_signals": 0,
            "successful_signals": 0,
            "win_rate": 0.0,
            "by_signal_type": {}
        }
        
        # Collect stats from all signal types
        for type_name, type_stats in self.signal_stats.items():
            if asset in type_stats["by_asset"]:
                asset_stats = type_stats["by_asset"][asset]
                
                stats["total_signals"] += asset_stats["count"]
                stats["successful_signals"] += asset_stats["wins"]
                
                stats["by_signal_type"][type_name] = {
                    "count": asset_stats["count"],
                    "wins": asset_stats["wins"],
                    "losses": asset_stats["losses"],
                    "win_rate": asset_stats["wins"] / asset_stats["count"] if asset_stats["count"] > 0 else 0
                }
        
        # Calculate overall win rate
        if stats["total_signals"] > 0:
            stats["win_rate"] = stats["successful_signals"] / stats["total_signals"]
        
        return stats
    
    # Background tasks
    
    async def _monitor_market_regimes(self):
        """Background task to monitor and update market regimes for all assets"""
        logger.debug("Starting market regime monitoring")
        
        while self.running:
            try:
                for asset in self.active_assets:
                    # Determine market regime for the asset
                    regime = await self.adaptive_learning.determine_market_regime(asset)
                    self.market_regimes[asset] = regime
                    
                    # Determine volatility regime
                    volatility = await self.adaptive_learning.determine_volatility_regime(asset)
                    self.volatility_regimes[asset] = volatility
                    
                    logger.debug(f"Updated regimes for {asset}: Market={regime}, Volatility={volatility}")
                
                # Update every 15 minutes
                await asyncio.sleep(900)
                
            except asyncio.CancelledError:
                logger.debug("Market regime monitoring cancelled")
                break
                
            except Exception as e:
                logger.error(f"Error in market regime monitoring: {e}")
                await asyncio.sleep(60)  # Retry after a minute
    
    async def _analyze_asset_correlations(self):
        """Background task to analyze correlations between assets"""
        logger.debug("Starting asset correlation analysis")
        
        while self.running:
            try:
                # Get all asset combinations
                assets = list(self.active_assets)
                
                # Calculate correlations
                correlation_matrix = await self.adaptive_learning.calculate_asset_correlations(assets)
                
                # Update correlation records
                for i, asset1 in enumerate(assets):
                    self.asset_correlations[asset1] = {}
                    for j, asset2 in enumerate(assets):
                        if i != j:  # Skip self-correlation
                            self.asset_correlations[asset1][asset2] = correlation_matrix[i, j]
                
                logger.debug(f"Updated correlations for {len(assets)} assets")
                
                # Update every 4 hours
                await asyncio.sleep(4 * 3600)
                
            except asyncio.CancelledError:
                logger.debug("Asset correlation analysis cancelled")
                break
                
            except Exception as e:
                logger.error(f"Error in asset correlation analysis: {e}")
                await asyncio.sleep(60)  # Retry after a minute
    
    async def _monitor_signal_expiration(self):
        """Background task to monitor and clean up expired signals"""
        logger.debug("Starting signal expiration monitoring")
        
        while self.running:
            try:
                now = datetime.utcnow()
                expired_count = 0
                
                # Find expired signals
                for signal_id, signal in list(self.active_signals.items()):
                    if signal.expiration and now > signal.expiration:
                        # Move to history
                        self.signal_history[signal_id] = signal
                        del self.active_signals[signal_id]
                        expired_count += 1
                
                if expired_count > 0:
                    logger.debug(f"Cleaned up {expired_count} expired signals")
                
                # Clean up old history entries (older than 7 days)
                cutoff = now - timedelta(days=7)
                old_history_count = 0
                
                for signal_id, signal in list(self.signal_history.items()):
                    if signal.timestamp < cutoff:
                        del self.signal_history[signal_id]
                        old_history_count += 1
                
                if old_history_count > 0:
                    logger.debug(f"Removed {old_history_count} old history entries")
                
                # Check every 5 minutes
                await asyncio.sleep(300)
                
            except asyncio.CancelledError:
                logger.debug("Signal expiration monitoring cancelled")
                break
                
            except Exception as e:
                logger.error(f"Error in signal expiration monitoring: {e}")
                await asyncio.sleep(60)  # Retry after a minute
    
    async def _evaluate_component_performance(self):
        """Background task to evaluate and record component performance"""
        logger.debug("Starting component performance evaluation")
        
        while self.running:
            try:
                # Evaluate pattern recognition performance
                pr_performance = await self.pattern_recognition.evaluate_performance()
                self.component_performance["pattern_recognition"] = pr_performance
                
                # Evaluate loophole detection performance
                ld_performance = await self.loophole_detection.evaluate_performance()
                self.component_performance["loophole_detection"] = ld_performance
                
                # Evaluate adaptive learning performance
                al_performance = await self.adaptive_learning.evaluate_performance()
                self.component_performance["adaptive_learning"] = al_performance
                
                logger.debug("Updated component performance metrics")
                
                # Record metrics
                for component, perf in self.component_performance.items():
                    for metric, value in perf.items():
                        if isinstance(value, (int, float)):
                            self.metrics.gauge(f"{component}_{metric}", value)
                
                # Update every hour
                await asyncio.sleep(3600)
                
            except asyncio.CancelledError:
                logger.debug("Component performance evaluation cancelled")
                break
                
            except Exception as e:
                logger.error(f"Error in component performance evaluation: {e}")
                await asyncio.sleep(60)  # Retry after a minute
    
    async def _run_adaptive_learning_cycle(self):
        """Background task to run the adaptive learning cycle"""
        logger.debug("Starting adaptive learning cycle")
        
        # Initialize with a delay to allow data collection
        await asyncio.sleep(3600)  # 1 hour initial delay
        
        while self.running:
            try:
                logger.info("Running adaptive learning cycle")
                
                # Execute the adaptive learning cycle
                await self.adaptive_learning.run_learning_cycle()
                
                # Update component strategies based on learning
                await self.pattern_recognition.update_strategies(
                    self.adaptive_learning.get_strategy_updates("pattern_recognition")
                )
                
                await self.loophole_detection.update_strategies(
                    self.adaptive_learning.get_strategy_updates("loophole_detection")
                )
                
                logger.info("Adaptive learning cycle completed")
                
                # Run every 24 hours (or as configured)
                cycle_interval = self.config.get(
                    "intelligence.adaptive_learning_interval_hours", 24
                )
                await asyncio.sleep(cycle_interval * 3600)
                
            except asyncio.CancelledError:
                logger.debug("Adaptive learning cycle cancelled")
                break
                
            except Exception as e:
                logger.error(f"Error in adaptive learning cycle: {e}")
                await asyncio.sleep(3600)  # Retry after an hour
